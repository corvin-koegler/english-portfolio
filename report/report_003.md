## Abstract
## Introduction

Software development and construction share many parallels and have historically been treated mostly the same. This historically extends to the project lifecycles. In the early days of software developers had to write large amounts of their code on paper because computer time was scarce and machines where still slow. Just like construction the job of the architect and the construction worker (programmer) were separated because both jobs called for a different skillset. The project got constructed on paper iterated on by multiple experts in different phases and ultimately constructed with the difference being that one field worked with steel and concrete and the other with text inputs.

In construction one of the most popular design approaches is the waterfall concept where the project flows down the different steps and then ends in a maintenance loop. Until recently software had to be treated similar because once shipped updates where bound to significant effort. With the internet the need for fully thought out products in software mostly vanished reducing the time from the drawing board to the customer significantly. While software and construction still share similarities the field of software engineering has evolved in a different direction. With CICD it's becoming increasingly popular to develop the product with the customer, continuously iterating and refining it.

Companies picked up on this and largely switched to agile developments techniques that are specifically designed to accommodate the new dynamic style of development. It is now significantly cheaper to bring a product to the customer and is even more normal to find beta state applications that are intentionally rapidly developing and instable. Because of software frameworks and libraries most base functionality is ready for production reducing the need for writing new software to the unique aspects of the projects.

Somewhere in this transition the traditional visualization tools lost most of their relevance. It's a significant overhead to update a UML diagram every time a library gets updated. And automatic tools never really gained traction in industry applications. While most traditional developers have to learn about UML diagrams and flowcharts during their education a significant chunk self thought developers don't. With modern tools it's not important enough to take the time to visualize the codebase until there is a good enough reason for it.

This report researches modern alternatives to the traditional visualization tools for software architecture discussing their advantages and drawbacks in comparison to traditional approaches and if there even is the need to use them anymore.

## Traditional Visualizations

Traditional visualization tools for software architecture are manually created. They specifically serve as a previous step to actually writing code and help picking up on unwanted dependencies, architectural code smells and other architectural issues. For example it's easy to see if demeters law was followed because in an UML Class diagrams its easy to spot violating connections between classes. Especially in the early days it was significantly faster to work out the rough code structure before writing the first line of code. The owner of the product specified what the code should do and developers constructed the architecture around that. Lastly programmers typed the code and fixed any errors emerging. If the code worked as intended and was tested enough it was ready to ship on a physical medium. If afterwards issues emerged it was logistically hard to bring a patch to the customer. 
### UML Diagrams

UML (Class) diagrams are a great tool to design the architecture of a application. While unnecessary on smaller projects its a great way to iterate on it before existing code prevents changes. In UML Diagrams the future code gets structured in classes planning out architectural patterns, needed methods, coupling and communication between classes and instances. Afterwards most of the code writing is simple enough to get handled asynchronously because the interface and shape is already defined. They are a great tool for teachers to test the understanding of students about architectural patterns without having to make them write large amounts of code.

They fit perfectly within the waterfall design approach because they allow building the whole structure of the project from the ground up and are fast to change. On larger projects with lots of connections they tend to become convoluted really fast. They do a good job in showing spatial relations between modules. In turn they clash with rapid development techniques because prototypes are applied when the solution is not yet fully found. In this case they have to be frequently altered manually meaning a significant work overhead. While it is possible to automatically generate them from existing code their application lies within planning new code and not really serving as a visualization of existing one. Modern technology makes it possible to enhance them at least slightly by introducing interactivity collapsing unwanted sections to clear some space.

Creating a UML diagram involves several steps to visually represent the architecture and design of a software application. Begin by identifying the key classes and components that will make up the system. Determine the relationships between these classes, such as inheritance, associations, and dependencies. Define the attributes and methods for each class, ensuring that they align with the planned functionality and design patterns. Arrange the classes and components spatially to reflect their relationships and interactions, using lines to connect them and arrows to indicate directionality of relationships. Label each class, attribute, method, and relationship clearly to provide comprehensive understanding. Regularly review and iterate on the diagram, making adjustments as needed to accommodate new insights or changes in the design

### Flow Charts

Flow charts are a great tool to describe what a application should feel like to the end user. By visualizing cause and effect they tend to be only marginally responsible for the architecture of the application. On the flip side the architecture is very influential on what flows are possible for the end product. Often legacy code can act blocking to desired flows in the application. Well structured code can mitigate this somewhat but building code with all possible changes in mind adds a significant chunk of overhead to the code. In general it's the fastest to write static code that relies on rigid systems to work. This is often used for prototypes because there is no real benefit from making explorative code well engineered if it has a high chance to be scrapped.

While traditionally one application was build for a single purpose due to resource limitations, popular modern applications tend to have a greater scope and therefore often no global user flow can be found. As an example the first versions of writing applications had a clear workflow that they inherited from typewriters. The user was supposed to either create a new document or open an existing one, make changes to it, touch up the format and aesthetics and then export it. Modern versions of word include extensive graphics libraries, AI interfaces and plugin systems and basic calculation frameworks. Within this a magnitude of different user flows are possible that the underlying architecture have to support.

Creating a flowchart involves a systematic approach to visually represent the sequence of actions or decisions within a process. Begin by identifying all the tasks, actions, or decisions that need to be mapped out. Determine the sequence of these tasks, noting any dependencies or conditions that influence the flow. Select appropriate symbols to represent different types of actions, such as rectangles for processes, diamonds for decision points, and arrows for the flow direction. Arrange these symbols on a canvas, ensuring a logical progression from the start point to the end point. Draw arrows to connect the symbols, clearly indicating the flow from one step to the next. Label each step and decision to provide clarity. If the process includes complex decision points or loops, ensure these are accurately represented to reflect potential variations in the flow. Regularly review and update the flowchart to accommodate any changes in the process or to incorporate additional details. While flowcharts can be generated automatically from code, they often require careful interpretation to ensure accuracy, especially when representing flexible and well-engineered architectures designed to support a variety of user interactions and future changes.

### Gnatt Diagrams

Gantt diagrams, or Gantt charts, are project management tools that represent the timeline of tasks or activities against a calendar. They illustrate the start and end dates of individual tasks, their durations, and their relationships with other tasks. In software development, Gantt charts are used to visualize the execution sequence of code, identifying which parts of the code run at specific times. This time-based visualization helps in finding bottlenecks by highlighting areas where tasks overlap excessively or wait for dependencies, indicating potential inefficiencies. By revealing these patterns, Gantt charts offer insights into possible sources of misconfiguration. Additionally, they can highlight indirect dependencies that may not be immediately apparent in the code structure but impact performance and execution. This information is crucial for optimizing both the architecture and the scheduling of tasks to improve overall system efficiency.

Creating a Gantt chart involves several systematic steps to visually represent the timeline and relationships of tasks or events. Beginning with listing all tasks, activities, or events that need to be tracked. For each task, determine the sequence and dependencies, identifying which tasks must precede or follow others. Assign start and end dates, or time periods, to each task, estimating the duration required for completion. Set up a timeline along the horizontal axis and list the tasks along the vertical axis. Draw bars to represent the duration of each task, with the position and length of each bar indicating the start time, duration, and end time. If necessary, connect tasks with arrows or lines to denote dependencies and relationships. Regularly update the chart to reflect any changes in the schedule or task progression.

## Modern Visualizations

Modern visualization approaches mostly failed to gain traction in industry applications. There seems to be a void between severely outdated tools from the beginning of the 2000s and futuristic ones made for augmented and virtual reality. While visualization is present in most modern development toolkits none aim directly to show the architecture or relation between files.

Most developers use a IDE to write their code. These come loaded with tools and plugins that sometimes leverage visualizations. As an example most IDEs bring a Git integration that visualizes evolutionary data about the project in a graph structure. While this is certainly useful the lack of architectural visualization is surprising. Most architectural and structural visualizations aim to grant researchers insights into open source repositories for analytics. Therefore most tools are somewhat one-off prototypes that serve in the research context and are dropped afterwards. A good chunk of them were developed in the early 2000s when UML and waterfall approaches were vastly more popular than today.
### Code Park

Code Park is a 3D software visualization tool that builds on the human understanding of spatial relations in the environment. It uses cities as metaphors for making the code approachable even in large project sizes. For example, buildings represent classes while districts represent packages/modules. The properties of the buildings, such as height and base size, can describe different metrics like lines of code in the class, number of methods, or complexity. Using these parameters, architectural flaws can show in overly big building or district sizes. The model is designed to allow exploration of existing code and integration with plugins that deepen the understanding of the user.

Code Park aims to improve a programmer’s understanding of an existing codebase in a manner that is both engaging and intuitive, appealing to novice users such as students. It achieves these goals by laying out the codebase in a 3D park-like environment. Each class in the codebase is represented as a 3D room-like structure. Constituent parts of the class (variables, member functions, etc.) are laid out on the walls, resembling a syntax-aware wallpaper. Users can interact with the codebase using an overview and a first-person viewer mode.

The tool is designed to explore the effects of spatial recognition when interacting with the codebase, featuring multiple view modes. These include an exocentric (bird’s eye) view and an ego-centric (first-person) view, allowing users to examine the codebase at different granularities. The bird’s eye view provides a holistic understanding of the codebase, while the first-person view enables a detailed exploration of individual classes. This dual-view approach helps users become familiar with and memorize the code structure more effectively.

Additionally, Code Park supports syntax parsing, enabling features like go-to definition, which allows users to quickly jump to the location where a variable or function is defined. This helps in mentally and visually connecting the disparate parts of the code together. The tool also incorporates animated transitions to maintain the user’s spatial awareness, making navigation intuitive and engaging.

While Code Park is a powerful tool in a research context, its application in a business environment presents several challenges. The use of the Unity game engine, while providing a rich and interactive 3D environment, also introduces significant resource overhead. This can lead to performance issues, particularly on lower-end hardware or when dealing with large codebases. Furthermore, the inability to integrate Code Park into existing Integrated Development Environments (IDEs) is a significant drawback. Developers often rely on the robust toolsets provided by their IDEs, and the lack of integration means they would have to constantly switch between the IDE and Code Park, disrupting their workflow. Another consideration is the portability of work. One of the appealing aspects of software development is the ability to work from anywhere, often on a laptop. However, the 3D visualization of Code Park requires a considerable amount of screen space, which is a luxury not always available on smaller laptop screens. This could potentially limit the usability of the tool for developers on the go. Lastly, the requirement for additional equipment, such as high-resolution monitors or even VR headsets for the best experience, may not be feasible or cost-effective for many organizations. This adds an extra layer of complexity and cost in a business setting, where budget constraints are a significant consideration.
### gource.io


## Conclusion